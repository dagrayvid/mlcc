{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run the notebook, you can either press the Run button above, or select each cell and press Shift+Enter, in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a convolutional neural network to classify images from the fashion MNIST dataset.\n",
    "\n",
    "The fashion MNIST dataset is a drop in replacement for the classic MNIST digit recognition dataset. Fashion MNIST contains 28x28 greyscale images of articles of clothing.\n",
    "\n",
    "They are labelled by digits 0-9 which have the following meanings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_meanings={0:\"T-Shirt/Top\", \n",
    "                1:\"Trouser\", \n",
    "                2:\"Pullover\", \n",
    "                3:\"Dress\", \n",
    "                4:\"Coat\",\n",
    "                5:\"Sandal\",\n",
    "                6:\"Shirt\",\n",
    "                7:\"Sneaker\",\n",
    "                8:\"Bag\",\n",
    "                9:\"Ankle Boot\"\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with importing the packages we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import gzip\n",
    "from os import path\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads the data from the /demo_data directory we passed as a volume into the container, into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "paths = []\n",
    "for fname in files:\n",
    "    paths.append(path.join('/demo_data', fname))\n",
    "    \n",
    "with gzip.open(paths[0], 'rb') as lbpath:\n",
    "    train_labels = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "with gzip.open(paths[1], 'rb') as imgpath:\n",
    "    train_data = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(train_labels), 28, 28)\n",
    "with gzip.open(paths[2], 'rb') as lbpath:\n",
    "    test_labels = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "with gzip.open(paths[3], 'rb') as imgpath:\n",
    "    test_data = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(test_labels), 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize some of the data using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "for i in range(24):\n",
    "    plt.subplot(3, 8, i+1)\n",
    "    digit_image = np.ones((28,28)) - test_data[10+i].reshape(28,28)\n",
    "    plt.imshow(digit_image, cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Examples of Fashion-MNIST Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell keras that our image data is in the form of an array of shape (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reshape our data accordingly, and set a variable to hold the shape of each individual image, which will be used when we set up the input layer of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "train_data = train_data.reshape(train_data.shape[0], img_rows, img_cols, 1)\n",
    "test_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will normalize each pixel value to a float32 value between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also convert the data labels from digits 0-9 to 'one-hot' encodings for our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is preprocessed, we can build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we set the model to use GPU's the Jupyter servers logs will show that the TensorFlow backend has access to them. \n",
    "\n",
    "#### Note: if your machine has a different number of gpus, change the gpus=# in the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=4, activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to set our loss function, and learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "              optimizer=keras.optimizers.Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "epochs = 8\n",
    "model.fit(train_data, train_labels,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=(test_data[:5000], test_labels[:5000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our model on the second half of the test data, which it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data[5000:], test_labels[5000:]\n",
    "                       ,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is about 90% accurate. Let's see where the model goes wrong.\n",
    "\n",
    "We can run the second half of the test data on the model, and save the inferred results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict_on_batch(test_data[5000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the model predicted on a few of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=6, figsize=(9,6))\n",
    "ax = axs.flat\n",
    "for i in range(18):\n",
    "    digit_image = np.ones((28,28)) - test_data[5000+i].reshape(28,28)\n",
    "    ax[i].imshow(digit_image, cmap='Greys_r')\n",
    "    ax[i].set_title(label_meanings[np.argmax(predicted[i])])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use scikit-learn to create a confusion matrix, and seaborn to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(np.argmax(test_labels[5000:],  axis=1), np.argmax(predicted, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "sns.set()\n",
    "sns.set_context(\"notebook\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(mat.T, annot=True, fmt='d', cbar=False, cmap=\"Blues\", \n",
    "            xticklabels=label_meanings.values(), yticklabels=label_meanings.values(),\n",
    "            norm=colors.SymLogNorm(vmin=mat.T.min(), vmax=mat.T.max(),  linthresh=5.0, linscale=10.0), ax=ax)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to:\n",
    "\n",
    "Keras examples: https://github.com/keras-team/keras/tree/master/examples\n",
    "\n",
    "These scikit learn examples for the idea of using a seaborn heatmap for a confusion matrix:\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
